{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5f737a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import cv2\n",
    "import gdown\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import shutil\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as tt\n",
    "import json\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision.utils import save_image\n",
    "from tqdm.notebook import tqdm\n",
    "#from google.colab import drive, files\n",
    "import nbimporter\n",
    "import copy\n",
    "import time\n",
    "\n",
    "from functions import *\n",
    "root = '.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "841bfe26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.applications.inception_v3 import preprocess_input\n",
    "from tensorflow.keras.models import Model\n",
    "from scipy.linalg import sqrtm\n",
    "\n",
    "def calculate_fid(image_path1, image_path2):\n",
    "    def calculate_activation_statistics(images, model):\n",
    "        print(images.shape)\n",
    "        act1 = model.predict(images)\n",
    "        act1 = act1.reshape(act1.shape[0], -1)\n",
    "        print(act1.shape)\n",
    "        mu, sigma = act1.mean(axis=0), np.cov(act1, rowvar=False)\n",
    "        return mu, sigma\n",
    "\n",
    "    def calculate_frechet_distance(mu1, sigma1, mu2, sigma2):\n",
    "        diff = mu1 - mu2\n",
    "        # Calculate the matrix square root of the product of sigma1 and sigma2\n",
    "        covmean = sqrtm(sigma1.dot(sigma2))\n",
    "        if np.iscomplexobj(covmean):\n",
    "            covmean = covmean.real\n",
    "        # Calculate FID\n",
    "        fid = np.dot(diff, diff) + np.trace(sigma1) + np.trace(sigma2) - 2 * np.trace(covmean)\n",
    "        return fid\n",
    "\n",
    "    # Load InceptionV3 model without top classification layer\n",
    "    inception_model = InceptionV3(include_top=False, pooling='avg', input_shape=(75, 75, 3))\n",
    "    inception_model = Model(inputs=inception_model.input, outputs=inception_model.layers[-2].output)\n",
    "\n",
    "    # Load and preprocess images\n",
    "    images1 = preprocess_input(load_and_preprocess_images(image_path1, (75, 75)))\n",
    "    images2 = preprocess_input(load_and_preprocess_images(image_path2, (75, 75)))\n",
    "\n",
    "    \n",
    "    mu1, sigma1 = calculate_activation_statistics(images1, inception_model)\n",
    "    mu2, sigma2 = calculate_activation_statistics(images2, inception_model)\n",
    "\n",
    "    # Calculate FID\n",
    "    fid = calculate_frechet_distance(mu1, sigma1, mu2, sigma2)\n",
    "    return fid\n",
    "\n",
    "def load_and_preprocess_images(image_path, target_size):\n",
    "    image_paths = [os.path.join(image_path, fname) for fname in os.listdir(image_path)]\n",
    "    images = [tf.keras.preprocessing.image.load_img(img_path, target_size=target_size) for img_path in image_paths]\n",
    "    images = [tf.keras.preprocessing.image.img_to_array(img).astype('float32') for img in images]\n",
    "    return np.array(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c17e4a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_photos(generator, model_name, device, latent_size, generator_path, photos_number):\n",
    "    current_directory = os.getcwd()\n",
    "    generator_path = 'tmp'\n",
    "    # Sprawdź, czy folder generator_path istnieje, jeśli nie, utwórz go\n",
    "    root = os.path.join(current_directory, generator_path)\n",
    "    if not os.path.exists(root):\n",
    "        os.makedirs(root)\n",
    "    for x in range(photos_number):\n",
    "        if model_name == 'lsgan':\n",
    "            fixed_latent = torch.randn(1, latent_size, device=device)\n",
    "        else:\n",
    "            fixed_latent = torch.randn(1, latent_size, 1, 1, device=device)\n",
    "        fake_images = generator(fixed_latent)\n",
    "\n",
    "        fake_fname = f'{x}.png'\n",
    "\n",
    "        # Utwórz pełną ścieżkę do pliku docelowego\n",
    "        fake_image_path = os.path.join(root, fake_fname)\n",
    "\n",
    "        try:\n",
    "            save_image(denorm(fake_images, stats), fake_image_path, nrow=8)\n",
    "        except Exception as e:\n",
    "            print(f'Błąd podczas zapisywania pliku: {e}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214dbd4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_fid = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcfec0cc",
   "metadata": {},
   "source": [
    "# Epochs FID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dcbbaca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read parameters\n"
     ]
    }
   ],
   "source": [
    "print(\"Read parameters\")\n",
    "stats = (0.5, 0.5, 0.5), (0.5, 0.5, 0.5)\n",
    "DATA_DIR = 'cats'\n",
    "image_size = 64\n",
    "train_ds = ImageFolder(DATA_DIR,\n",
    "                       transform=tt.Compose([tt.Resize(image_size),\n",
    "                                             tt.CenterCrop(image_size),\n",
    "                                             tt.ToTensor(),\n",
    "                                             tt.Normalize(*stats)]))\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "epochs = 55\n",
    "lr = 0.0002\n",
    "batch_size = 128\n",
    "latent_size = 128\n",
    "DATA_DIR = 'cats'\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
    "train_dl = DeviceDataLoader(train_dl, device)\n",
    "model_name = 'basic'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c33f93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start\n",
      "OK\n",
      "Warning: batch size is bigger than the data size. Setting batch size to data size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:04<00:00,  4.56s/it]\n"
     ]
    }
   ],
   "source": [
    "print('Start')\n",
    "epochs_fid = {}\n",
    "epochsss = [5, 15, 30, 50, 100]\n",
    "exp_title = 'test_epochs'\n",
    "photos_number = 15747\n",
    "del epochs\n",
    "for exp_index, epochs in enumerate(epochsss):\n",
    "    generator_path = 'generator_' + exp_title + '_' + str(exp_index) + '_' + model_name\n",
    "    generator = get_generator(device, latent_size, model_name)\n",
    "    generator.load_state_dict(torch.load(f'{generator_path}'))\n",
    "    gen_photos(generator, model_name, device, latent_size, generator_path, photos_number)\n",
    "    print(\"OK\")\n",
    "    epochsss = {exp_index: calculate_fid(r'C:\\Users\\karol\\Downloads\\lista-1-KunickiKarol-main\\cats_1000', \n",
    "          r'C:\\Users\\karol\\Downloads\\lista-1-KunickiKarol-main\\tmp')}\n",
    "all_fid.append(epochsss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb1fa7b",
   "metadata": {},
   "source": [
    "# LR FID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef915dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Read parameters\")\n",
    "stats = (0.5, 0.5, 0.5), (0.5, 0.5, 0.5)\n",
    "DATA_DIR = 'cats'\n",
    "image_size = 64\n",
    "train_ds = ImageFolder(DATA_DIR,\n",
    "                       transform=tt.Compose([tt.Resize(image_size),\n",
    "                                             tt.CenterCrop(image_size),\n",
    "                                             tt.ToTensor(),\n",
    "                                             tt.Normalize(*stats)]))\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "epochs = 55\n",
    "lr = 0.0002\n",
    "batch_size = 128\n",
    "latent_size = 128\n",
    "DATA_DIR = 'cats'\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
    "train_dl = DeviceDataLoader(train_dl, device)\n",
    "model_name = 'basic'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de85aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Start')\n",
    "lrs = [0.00005, 0.0001, 0.0002, 0.0004, 0.0006]\n",
    "exp_title = 'test_lr'\n",
    "lrs = {}\n",
    "del lr\n",
    "for exp_index, lr in enumerate(lrs):\n",
    "    generator_path = 'generator_' + exp_title + '_' + str(exp_index) + '_' + model_name\n",
    "    generator = get_generator(device, latent_size, model_name)\n",
    "    generator.load_state_dict(torch.load(f'{generator_path}'))\n",
    "    gen_photos(generator, model_name, device, latent_size, generator_path, photos_number)\n",
    "    print(\"OK\")\n",
    "    lrs = {exp_index: calculate_fid(r'C:\\Users\\karol\\Downloads\\lista-1-KunickiKarol-main\\cats_1000', \n",
    "          r'C:\\Users\\karol\\Downloads\\lista-1-KunickiKarol-main\\tmp')}\n",
    "all_fid.append(lrs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb3adfb",
   "metadata": {},
   "source": [
    "# Batch size FID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05efeee",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Read parameters\")\n",
    "stats = (0.5, 0.5, 0.5), (0.5, 0.5, 0.5)\n",
    "DATA_DIR = 'cats'\n",
    "image_size = 64\n",
    "train_ds = ImageFolder(DATA_DIR,\n",
    "                       transform=tt.Compose([tt.Resize(image_size),\n",
    "                                             tt.CenterCrop(image_size),\n",
    "                                             tt.ToTensor(),\n",
    "                                             tt.Normalize(*stats)]))\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "epochs = 55\n",
    "lr = 0.0002\n",
    "batch_size = 128\n",
    "latent_size = 128\n",
    "DATA_DIR = 'cats'\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
    "train_dl = DeviceDataLoader(train_dl, device)\n",
    "model_name = 'basic'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6a0983",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Start')\n",
    "batch_sizes = [8, 32, 128, 512, 1024]\n",
    "exp_title = 'test_batch'\n",
    "batches = {}\n",
    "del batch_size\n",
    "for exp_index, batch_size in enumerate(batch_sizes):\n",
    "    generator_path = 'generator_' + exp_title + '_' + str(exp_index) + '_' + model_name\n",
    "    generator = get_generator(device, latent_size, model_name)\n",
    "    generator.load_state_dict(torch.load(f'{generator_path}'))\n",
    "    gen_photos(generator, model_name, device, latent_size, generator_path, photos_number)\n",
    "    print(\"OK\")\n",
    "    batches = {exp_index: calculate_fid(r'C:\\Users\\karol\\Downloads\\lista-1-KunickiKarol-main\\cats_1000', \n",
    "          r'C:\\Users\\karol\\Downloads\\lista-1-KunickiKarol-main\\tmp')}\n",
    "all_fid.append(batches)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78062a99",
   "metadata": {},
   "source": [
    "# Latent FID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e56158",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Read parameters\")\n",
    "stats = (0.5, 0.5, 0.5), (0.5, 0.5, 0.5)\n",
    "DATA_DIR = 'cats'\n",
    "image_size = 64\n",
    "train_ds = ImageFolder(DATA_DIR,\n",
    "                       transform=tt.Compose([tt.Resize(image_size),\n",
    "                                             tt.CenterCrop(image_size),\n",
    "                                             tt.ToTensor(),\n",
    "                                             tt.Normalize(*stats)]))\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "epochs = 55\n",
    "lr = 0.0002\n",
    "batch_size = 128\n",
    "latent_size = 128\n",
    "DATA_DIR = 'cats'\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
    "train_dl = DeviceDataLoader(train_dl, device)\n",
    "model_name = 'basic'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e617ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Start')\n",
    "latent_sizes = [8, 32, 128, 512, 1024]\n",
    "exp_title = 'test_latent'\n",
    "del latent_size\n",
    "latents = {}\n",
    "for exp_index, latent_size in enumerate(latent_sizes):   \n",
    "    generator_path = 'generator_' + exp_title + '_' + str(exp_index) + '_' + model_name\n",
    "    generator = get_generator(device, latent_size, model_name)\n",
    "    generator.load_state_dict(torch.load(f'{generator_path}'))\n",
    "    gen_photos(generator, model_name, device, latent_size, generator_path, photos_number)\n",
    "    print(\"OK\")\n",
    "    latents = {exp_index: calculate_fid(r'C:\\Users\\karol\\Downloads\\lista-1-KunickiKarol-main\\cats_1000', \n",
    "          r'C:\\Users\\karol\\Downloads\\lista-1-KunickiKarol-main\\tmp')}\n",
    "all_fid.append(latents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e97fbfe",
   "metadata": {},
   "source": [
    "# Optimizer FID\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1defc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Read parameters\")\n",
    "stats = (0.5, 0.5, 0.5), (0.5, 0.5, 0.5)\n",
    "DATA_DIR = 'cats'\n",
    "image_size = 64\n",
    "latent_size = 128\n",
    "train_ds = ImageFolder(DATA_DIR,\n",
    "                       transform=tt.Compose([tt.Resize(image_size),\n",
    "                                             tt.CenterCrop(image_size),\n",
    "                                             tt.ToTensor(),\n",
    "                                             tt.Normalize(*stats)]))\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "epochs = 55\n",
    "lr = 0.0002\n",
    "batch_size = 128\n",
    "latent_size = 128\n",
    "DATA_DIR = 'cats'\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
    "train_dl = DeviceDataLoader(train_dl, device)\n",
    "model_name = 'basic'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486f99c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Start')\n",
    "optimizers_list = [torch.optim.RAdam, torch.optim.NAdam, torch.optim.AdamW, torch.optim.Adam]\n",
    "exp_title = 'test_optimizer'\n",
    "optimizerXXX = {}\n",
    "for exp_index, optimizer_test in enumerate(optimizers_list):   \n",
    "    generator_path = 'generator_' + exp_title + '_' + str(exp_index) + '_' + model_name\n",
    "    generator = get_generator(device, latent_size, model_name)\n",
    "    generator.load_state_dict(torch.load(f'{generator_path}'))\n",
    "    gen_photos(generator, model_name, device, latent_size, generator_path, photos_number)\n",
    "    print(\"OK\")\n",
    "    optimizerXXX = {exp_index: calculate_fid(r'C:\\Users\\karol\\Downloads\\lista-1-KunickiKarol-main\\cats_1000', \n",
    "          r'C:\\Users\\karol\\Downloads\\lista-1-KunickiKarol-main\\tmp')}\n",
    "all_fid.append(optimizerXXX)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e82333ef",
   "metadata": {},
   "source": [
    "# Loss FID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19221183",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Read parameters\")\n",
    "stats = (0.5, 0.5, 0.5), (0.5, 0.5, 0.5)\n",
    "DATA_DIR = 'cats'\n",
    "image_size = 64\n",
    "latent_size = 128\n",
    "train_ds = ImageFolder(DATA_DIR,\n",
    "                       transform=tt.Compose([tt.Resize(image_size),\n",
    "                                             tt.CenterCrop(image_size),\n",
    "                                             tt.ToTensor(),\n",
    "                                             tt.Normalize(*stats)]))\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "epochs = 55\n",
    "lr = 0.0002\n",
    "batch_size = 128\n",
    "latent_size = 128\n",
    "DATA_DIR = 'cats'\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
    "train_dl = DeviceDataLoader(train_dl, device)\n",
    "model_name = 'basic'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b33a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Start')\n",
    "loss_list = [nn.MSELoss, nn.BCELoss]\n",
    "exp_title = 'test_loss'\n",
    "lossesXXX = {}\n",
    "for exp_index, lost_test in enumerate(loss_list):   \n",
    "    generator_path = 'generator_' + exp_title + '_' + str(exp_index) + '_' + model_name\n",
    "    generator = get_generator(device, latent_size, model_name)\n",
    "    generator.load_state_dict(torch.load(f'{generator_path}'))\n",
    "    gen_photos(generator, model_name, device, latent_size, generator_path, photos_number)\n",
    "    print(\"OK\")\n",
    "    lossesXXX = {exp_index: calculate_fid(r'C:\\Users\\karol\\Downloads\\lista-1-KunickiKarol-main\\cats_1000', \n",
    "          r'C:\\Users\\karol\\Downloads\\lista-1-KunickiKarol-main\\tmp')}\n",
    "all_fid.append(lossesXXX)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb61557",
   "metadata": {},
   "source": [
    "# Model FID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9fbea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Read parameters\")\n",
    "stats = (0.5, 0.5, 0.5), (0.5, 0.5, 0.5)\n",
    "DATA_DIR = 'cats'\n",
    "image_size = 64\n",
    "latent_size = 128\n",
    "train_ds = ImageFolder(DATA_DIR,\n",
    "                       transform=tt.Compose([tt.Resize(image_size),\n",
    "                                             tt.CenterCrop(image_size),\n",
    "                                             tt.ToTensor(),\n",
    "                                             tt.Normalize(*stats)]))\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "epochs = 55\n",
    "lr = 0.0002\n",
    "batch_size = 128\n",
    "latent_size = 128\n",
    "DATA_DIR = 'cats'\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
    "train_dl = DeviceDataLoader(train_dl, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37516e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Start')\n",
    "loss_list = [nn.MSELoss, nn.BCELoss]\n",
    "model_names = ['lsgan', 'basic']\n",
    "weights_types = [True, False]\n",
    "exp_title = 'test_models'\n",
    "exp_index = 0\n",
    "modelsXXX = {}\n",
    "for loss_test in loss_list:\n",
    "    for model_name in model_names:\n",
    "        for weight_type in weights_types:\n",
    "            if loss_test == nn.BCELoss and model_name == 'lsgan':\n",
    "                continue\n",
    "\n",
    "\n",
    "            generator_path = 'generator_' + exp_title + '_' + str(exp_index) + '_' + model_name\n",
    "            generator = get_generator(device, latent_size, model_name)\n",
    "            generator.load_state_dict(torch.load(f'{generator_path}'))\n",
    "            gen_photos(generator, model_name, device, latent_size, generator_path, photos_number)\n",
    "            print(\"OK\")\n",
    "            modelsXXX = {exp_index: calculate_fid(r'C:\\Users\\karol\\Downloads\\lista-1-KunickiKarol-main\\cats_1000', \n",
    "                  r'C:\\Users\\karol\\Downloads\\lista-1-KunickiKarol-main\\tmp')}\n",
    "            exp_index += 1\n",
    "all_fid.append(modelsXXX)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e23aee6c",
   "metadata": {},
   "source": [
    "# Architekra FID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027a7e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Read parameters\")\n",
    "stats = (0.5, 0.5, 0.5), (0.5, 0.5, 0.5)\n",
    "DATA_DIR = 'cats'\n",
    "image_size = 64\n",
    "latent_size = 128\n",
    "train_ds = ImageFolder(DATA_DIR,\n",
    "                       transform=tt.Compose([tt.Resize(image_size),\n",
    "                                             tt.CenterCrop(image_size),\n",
    "                                             tt.ToTensor(),\n",
    "                                             tt.Normalize(*stats)]))\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "epochs = 55\n",
    "lr = 0.0002\n",
    "batch_size = 128\n",
    "latent_size = 128\n",
    "DATA_DIR = 'cats'\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
    "train_dl = DeviceDataLoader(train_dl, device)\n",
    "model_name = 'basic'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b50101",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Start')\n",
    "activations_gen = [nn.ReLU(True), nn.LeakyReLU(0.2, inplace=True), nn.LeakyReLU(0.5, inplace=True)]\n",
    "activations_dis = [nn.LeakyReLU(0.2, inplace=True), nn.ReLU(True), nn.LeakyReLU(0.5, inplace=True)]\n",
    "exp_title = 'test_arch_trash'\n",
    "exp_index = 0\n",
    "architer = {}\n",
    "for activation_gen in enumerate(activations_gen): \n",
    "    for activation_dis in enumerate(activations_dis):\n",
    "        generator_path = 'generator_' + exp_title + '_' + str(exp_index) + '_' + model_name\n",
    "        generator = get_generator(device, latent_size, model_name)\n",
    "        generator.load_state_dict(torch.load(f'{generator_path}'))\n",
    "        gen_photos(generator, model_name, device, latent_size, generator_path, photos_number)\n",
    "        print(\"OK\")\n",
    "        architer = {exp_index: calculate_fid(r'C:\\Users\\karol\\Downloads\\lista-1-KunickiKarol-main\\cats_1000', \n",
    "              r'C:\\Users\\karol\\Downloads\\lista-1-KunickiKarol-main\\tmp')}\n",
    "        exp_index += 1\n",
    "all_fid.append(architer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f521eff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import cv2\n",
    "import gdown\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import shutil\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as tt\n",
    "import json\n",
    "import plotly.express as px\n",
    "import plotly.subplots\n",
    "import plotly.graph_objs as go\n",
    "import pandas as pd\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision.utils import save_image\n",
    "from tqdm.notebook import tqdm\n",
    "#from google.colab import drive, files\n",
    "import nbimporter\n",
    "import copy\n",
    "import time\n",
    "\n",
    "from functions import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e42f4cb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "basic\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model = load_model(device, 'basic', 'discriminator_test_optimizer_3_basic', 'generator_test_optimizer_3_basic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ffb9ad1e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fixed_latent' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m stats \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m0.5\u001b[39m), (\u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m0.5\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m fake_images \u001b[38;5;241m=\u001b[39m model[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgenerator\u001b[39m\u001b[38;5;124m'\u001b[39m](\u001b[43mfixed_latent\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'fixed_latent' is not defined"
     ]
    }
   ],
   "source": [
    "stats = (0.5, 0.5, 0.5), (0.5, 0.5, 0.5)\n",
    "\n",
    "fake_images = model['generator'](fixed_latent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef93592",
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_pixel(main_tensor, how_many): \n",
    "    pixels = []\n",
    "    for i in range(64):\n",
    "        image_pixels = []\n",
    "        for pixel in range(how_many):\n",
    "            pixel = np.random.randint(128)\n",
    "            random_val = np.random.randn(1)[0]\n",
    "            image_pixels.append({'pixel': pixel, 'val': random_val})\n",
    "            main_tensor[i, pixel, 0, 0] = np.random.randn(1)[0]\n",
    "        pixels.append(image_pixels)\n",
    "    \n",
    "    return main_tensor, pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0514e9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# <<0 ten sam obrazek, 0 ten sam obrazek, 0>> ten sam obrazek\n",
    "fixed_latent = torch.full((1, 128, 1, 1), 0.0007, device=device)\n",
    "fake_fname = '1.png'\n",
    "with torch.no_grad():\n",
    "    fake_images = model['generator'](fixed_latent)\n",
    "save_image(denorm(fake_images, stats), os.path.join('.', fake_fname), nrow=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b9f8405f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'pixel': 109, 'val': 0.1199786553562134}],\n",
       " [{'pixel': 20, 'val': 1.2661895586192273}],\n",
       " [{'pixel': 52, 'val': -0.028776486802461015}],\n",
       " [{'pixel': 26, 'val': 1.0414999426973075}],\n",
       " [{'pixel': 116, 'val': 0.09042143661118134}],\n",
       " [{'pixel': 8, 'val': -1.918722053986832}],\n",
       " [{'pixel': 108, 'val': -0.03527244297695346}],\n",
       " [{'pixel': 61, 'val': 0.31721444062129317}],\n",
       " [{'pixel': 65, 'val': -1.9224527730191707}],\n",
       " [{'pixel': 16, 'val': -0.05705281385971481}],\n",
       " [{'pixel': 40, 'val': 2.613334607433692}],\n",
       " [{'pixel': 124, 'val': 0.19233918217758783}],\n",
       " [{'pixel': 97, 'val': -0.7554319899148956}],\n",
       " [{'pixel': 4, 'val': 0.33217184462757365}],\n",
       " [{'pixel': 90, 'val': -1.2198564212374399}],\n",
       " [{'pixel': 92, 'val': -0.16322542636226947}],\n",
       " [{'pixel': 55, 'val': 0.3126039272574543}],\n",
       " [{'pixel': 54, 'val': -1.0977938255379482}],\n",
       " [{'pixel': 82, 'val': 0.4563470457758781}],\n",
       " [{'pixel': 73, 'val': -0.34824613515708863}],\n",
       " [{'pixel': 81, 'val': 0.6138189554997834}],\n",
       " [{'pixel': 100, 'val': 0.3396028224076162}],\n",
       " [{'pixel': 8, 'val': 1.3718054252381098}],\n",
       " [{'pixel': 53, 'val': 0.9446307367334287}],\n",
       " [{'pixel': 100, 'val': 0.9120725134468589}],\n",
       " [{'pixel': 54, 'val': -0.3614902230374252}],\n",
       " [{'pixel': 119, 'val': -0.8834070169200849}],\n",
       " [{'pixel': 51, 'val': -1.1256254035631066}],\n",
       " [{'pixel': 72, 'val': 0.3469411784272174}],\n",
       " [{'pixel': 112, 'val': -0.11304934328623868}],\n",
       " [{'pixel': 112, 'val': 1.123673501040537}],\n",
       " [{'pixel': 111, 'val': -1.073780061108013}],\n",
       " [{'pixel': 78, 'val': -0.179689239012413}],\n",
       " [{'pixel': 116, 'val': -2.019948914977804}],\n",
       " [{'pixel': 106, 'val': -1.0049702824083724}],\n",
       " [{'pixel': 80, 'val': -0.4575608310285251}],\n",
       " [{'pixel': 37, 'val': -0.10174979257173548}],\n",
       " [{'pixel': 21, 'val': -2.3427501276336202}],\n",
       " [{'pixel': 75, 'val': -1.6786503420314358}],\n",
       " [{'pixel': 91, 'val': -1.5649476967839213}],\n",
       " [{'pixel': 79, 'val': -0.08513133234600666}],\n",
       " [{'pixel': 121, 'val': 0.08793083585581418}],\n",
       " [{'pixel': 68, 'val': 1.2149796747146884}],\n",
       " [{'pixel': 4, 'val': 0.2836804946134193}],\n",
       " [{'pixel': 59, 'val': -0.38173026883817524}],\n",
       " [{'pixel': 11, 'val': -0.6867920694997054}],\n",
       " [{'pixel': 29, 'val': -0.0015208190460758715}],\n",
       " [{'pixel': 56, 'val': -0.8742197478997424}],\n",
       " [{'pixel': 5, 'val': -1.6688184370353025}],\n",
       " [{'pixel': 70, 'val': 0.643396249013894}],\n",
       " [{'pixel': 41, 'val': 0.29330894437295435}],\n",
       " [{'pixel': 22, 'val': -0.17224150964695625}],\n",
       " [{'pixel': 116, 'val': -0.20903330422819816}],\n",
       " [{'pixel': 85, 'val': -0.03028088626919285}],\n",
       " [{'pixel': 22, 'val': 0.29986539480584884}],\n",
       " [{'pixel': 14, 'val': 0.6692371183857857}],\n",
       " [{'pixel': 75, 'val': 0.6170321220232245}],\n",
       " [{'pixel': 86, 'val': 0.8585423679377998}],\n",
       " [{'pixel': 8, 'val': -1.42262780185726}],\n",
       " [{'pixel': 21, 'val': -1.700663729626189}],\n",
       " [{'pixel': 36, 'val': 0.22551409205521306}],\n",
       " [{'pixel': 24, 'val': -1.438620973491001}],\n",
       " [{'pixel': 111, 'val': 0.7410402934257301}],\n",
       " [{'pixel': 73, 'val': -0.8497872256002915}]]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nawet jeden 'pixel' duzo zmienia chociaz i tak duża część obrazów jest szara\n",
    "fixed_latent, pixels = change_pixel(torch.zeros(64, 128, 1, 1, device=device), 1)\n",
    "fake_fname = '0.png'\n",
    "with torch.no_grad():\n",
    "    fake_images = model['generator'](fixed_latent)\n",
    "save_image(denorm(fake_images, stats), os.path.join('.', fake_fname), nrow=8)\n",
    "pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2aac2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generuj_liste(minimum, maximum):\n",
    "    krok = (maximum - minimum) / 64\n",
    "    elementy = [minimum + i * krok for i in range(65)]  # 65 elementów, aby uzyskać 64 kroki\n",
    "    return elementy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c2c701a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_pixel_range(main_tensor, pixel_idx, minimum, maximum): \n",
    "    change_range = generuj_liste(minimum, maximum)\n",
    "    for i in range(64):\n",
    "        main_tensor[i, pixel_idx, 0, 0] = change_range[i]\n",
    "        print(change_range[i])\n",
    "    return main_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a51892a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "15.625\n",
      "31.25\n",
      "46.875\n",
      "62.5\n",
      "78.125\n",
      "93.75\n",
      "109.375\n",
      "125.0\n",
      "140.625\n",
      "156.25\n",
      "171.875\n",
      "187.5\n",
      "203.125\n",
      "218.75\n",
      "234.375\n",
      "250.0\n",
      "265.625\n",
      "281.25\n",
      "296.875\n",
      "312.5\n",
      "328.125\n",
      "343.75\n",
      "359.375\n",
      "375.0\n",
      "390.625\n",
      "406.25\n",
      "421.875\n",
      "437.5\n",
      "453.125\n",
      "468.75\n",
      "484.375\n",
      "500.0\n",
      "515.625\n",
      "531.25\n",
      "546.875\n",
      "562.5\n",
      "578.125\n",
      "593.75\n",
      "609.375\n",
      "625.0\n",
      "640.625\n",
      "656.25\n",
      "671.875\n",
      "687.5\n",
      "703.125\n",
      "718.75\n",
      "734.375\n",
      "750.0\n",
      "765.625\n",
      "781.25\n",
      "796.875\n",
      "812.5\n",
      "828.125\n",
      "843.75\n",
      "859.375\n",
      "875.0\n",
      "890.625\n",
      "906.25\n",
      "921.875\n",
      "937.5\n",
      "953.125\n",
      "968.75\n",
      "984.375\n"
     ]
    }
   ],
   "source": [
    "# bug pythona? jakieś 'modulo' w sieci?\n",
    "fixed_latent =check_pixel_range(torch.zeros(64, 128, 1, 1, device=device), 0, 0, 1000)\n",
    "fake_fname = '11.png'\n",
    "with torch.no_grad():\n",
    "    fake_images = model['generator'](fixed_latent)\n",
    "save_image(denorm(fake_images, stats), os.path.join('.', fake_fname), nrow=8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c530fd08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
